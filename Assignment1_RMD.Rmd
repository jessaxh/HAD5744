---
name: Husayn Jessa and Aidan Bodner
title: "Assignment 1"
output: html_document
date: '2022-09-30'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Assignment Intro}

name <- Sys.info()
name[7]

### Load the packages we will need for this file ####

library(tidyverse) # load the installed package for each new session of R
library(broom) # helps for storing regression output
library(here) # for file organization
library(modelsummary) # For making regression tables
library(psych) # For creating summary statistics table
library(countrycode) # Used to get continents from countries
library(fastDummies) # To create dummy variables
library(vtable)
# enter file path identifiers
here("Desktop", "Graduate Studies", "4. Courses", "Fall 2022", "HAD5744H", "Assignments", "Assignment 1")

assign_data <- read.csv("Dataset 1.csv") # assign data to an object

```

--------------------------------------------------------------------------------

```{r Clean Data}

# Scan through dataframe to see variable class types
for(values in names(assign_data)){
  print(names(assign_data[values]))
  name <- names(assign_data[values])
  print(class(assign_data[,values]))
}

# Convert all to character
assign_data[, 1:19] <- lapply(assign_data[, 1:19], as.character)

# Assign the NAs in dataset to NA
assign_data <- mutate_at(.tbl = assign_data, 
                                .vars = vars(Country:PctPop65Pl2005), 
                                .funs = ~case_when(. == "#N/A" ~ NA_character_,
                                                   . == "-" ~ NA_character_,
                                                   TRUE ~ .,
                                                   TRUE ~ as.character(NA_character_)))

# Save cleaned data
write.csv(assign_data, "Dataset 1_Clean.csv", row.names = FALSE)

# Read in cleaned data
Dataset1 <- read.csv("Dataset 1_Clean.csv")

# Convert to numerics (aside from Country)
Dataset1[, 2:19] <- lapply(Dataset1[, 2:19], as.numeric)
```

--------------------------------------------------------------------------------

Question 1: Draw a preliminary DAG for the following variables: LEBF, GDPPC
 HXPC, total fertility rate, and any other covarites of relevance;ensure
relationships between the other independent variables is included
```{r Question No.1}

```

--------------------------------------------------------------------------------

Question 2: What does your DAG tell you about interpreting any regression coefficients
causally 

A DAG can allow for causal interpretations of regression coefficient if all the back door paths
represented in the DAG are closed and if the assumptions that are made to design and create the 
relationships within the DAG are correct (all the variable positions in the DAG are justified and
how their relationships are depicted are correct). When examining our DAG, we are not able to 
interpret our regression coefficients causally because we are unable to confirm that we have made
the correct assumptions within our DAG nor if they are the right ones to depict the relationship at hand. 

--------------------------------------------------------------------------------

Question 3: Make a table providing summary statistics for your variables;
table should include the mean, standard deviation and sample size for each variable Does anything of concern stand out to you? 
```{r summary table}
describe(Dataset1)
summary_table <- describe(Dataset1[ ,c("LEBF20052","maxINFM20052","GDPPCUS2005", "HXPC2005","PctHXPUB2005",
                   "TotFertRate2005","AdolFertRt2005","FtoMPrimaryEnrl2005ONY",
                   "PctUrb2005", "Sanitation2005ONY","ImprWaterUrb2005ONY",
                   "ImpWatRur2005ONY", "FLFPR2005", "PctPop0142005", "PctPop65Pl2005")],
                  fast=TRUE) 
summary_table <- summary_table[ ,-(1), drop = FALSE] #drop first column which corresponds to variable number in dataframe

summary_table
```

#Does anything of concern stand out to you? <- we have to add this
--------------------------------------------------------------------------------

Question 4 - Regress LEBF on HXPC. Report the coefficients,standard errors, confidence intervals, p-values, R2, and sample size in a regression table. Interpret the table, noting the economic and statistical significance of the relationship. What is the association between a 1,000-unit increase in HXPC and LEBF? (Note that HXPC is measured in dollars.)

```{r first regression}
first_regression <- lm(LEBF20052~HXPC2005, Dataset1)
Regression_table1 <- msummary(first_regression, fmt = "%.4f",
                              stars=c('*' = .1, '**' = .05, '***' = .01), 
                              statistic = c("conf.int",  "standard error = {std.error}", 
                                            "p-value = {p.value}")
)         
Regression_table1
```

The table shows that Health expenditure has a significant effect on the life expectancy at birth for females.This is economically significant because it shows that investment in Health expenditure is related to a longer life expectancy for females at birth. This provides the government with information on potential resource allocation. The table shows that a one unit increase in health expenditure leads to a 0.0040 increase in the life expectancy of females at birth. If there was a $1000 increase in health expenditure the life expectancy of females at birth would increase by 4 units. 
#maybe we need to talk about the standard errors/pvalues?

--------------------------------------------------------------------------------

Question 5 - Regress LEBF on HXPC and GDPPC - Discuss the results of this regression relative
to those from Question 4
```{r Question No.5}

second_regression <- lm(LEBF20052~HXPC2005+GDPPCUS2005, Dataset1)
Regression_table2 <- msummary(list(first_regression,second_regression), 
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                              fmt = "%.4f",  statistic = c("conf.int",  "standard error 
                                                           ={std.error}", 
                                            "p-value = {p.value}"))
Regression_table2
```

The results of this regression show that when GDPPC is controlled for the effects
of HXPC are no longer statistically significant.The regression coefficient of HXPC becomes reduced in this new model, going from 0.004 to -0.001. The new coefficient for Health Expenditure is negative which would mean increased health expenditure is related to a reduction in life expectancy. We would generally expect an increase in health expenditure to be positively related to life expectancy, thus it makes sense why these results are no longer significant. The regression coefficient for GDP is 0.0005 and is statistically significant. This provides indication that there is a relationship between GDDPC and LEBF. For every one unit increase in GDP, LEBF will increase by 0.0005 units. 

--------------------------------------------------------------------------------

Question 6 - Do you recommend a nonlinear transformation for either GDPPC, HXPC, or LEBF? If so, defend your choice and repeat the regression in (5) with the appropriate transformations. Interpret how your results have changed. [10 points]
```{r Question No.6}

# Visually, look and see how well the observations fit the linear model

vtable(Dataset1)
attach(Dataset1)
hist(GDPPCUS2005)        
hist(log(GDPPCUS2005))
hist(HXPC2005)
hist(log(HXPC2005))

ggplot(Dataset1, aes(x = HXPC2005, y = LEBF20052)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red")

ggplot(Dataset1, aes(x = GDPPCUS2005, y = LEBF20052)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red")
```

The histograms of GDPPC and HXPC show that their data is rightly skewed and thus is likely to produce outliers. Additionally, looking at how well the observations fit around the regression line, we can see that the plots for both GDDPC and HXPC do not fit the regression line well. We recommend, doing a log transformation of these two variables because it will make the big observations in the data smaller and thus closer to the other variables in the data. This will help reduce the skew and help the model behave more effectively.The histograms of the log transformed variables show that when a log transformation is performed the data looks approximately fits a normal distribution which is helpful for drawing statistical inference. 

```{r Question No. 6 pt 2}
third_regression <- lm(LEBF20052~log(HXPC2005)+log(GDPPCUS2005), Dataset1)
Regression_table3 <- msummary(list(second_regression, third_regression), 
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                              fmt = "%.4f",  statistic = c("conf.int",  "standard error 
                                                           ={std.error}", 
                                            "p-value = {p.value}"))
Regression_table3
```

Applying a non-linear transformation is necessary in order to reduce the extreme effects of outliers on our regression outputs. Log transforming the predictor variables in the regression model is one way in which we can achieve this. It makes sense to log transform the independent variables in the model by applying a natural log, as we can directly compare the regression output to those in (5) as the output stays in the same units. We are also able to apply the natural log as we do not have any zero-valued data.

By log transforming both HXPC and GDPPC we are provided with new regression coefficients. The regression coefficient of log(HXPC2005) is now 0.8886 which is substantially different than the non-log'd coefficient -0.0014. The new regression coefficient indicates that for every 10% increase in HXPC (when GDPPC is held constant), the LEBF will increase by 0.089. Intuitively, life expectancy should increase as there is more health expenditure within a country so these new results make more sense which speaks to the value of transforming the HXPC variable. The results however remain statisically insignificant. The regression coefficient for log(GDPPCUS2005) also changed to 4.114 which is an increase from the non-log'd coefficient of 0.0005. Both coefficients were deemed as statistically significant. The new regression coefficient indicates that for every 10% increase in GDP (when HXPC is held constant) there is a 0.4114 increase in life expectancy at birth for females. We can also see that the R^2 value has increased from 0.252 to 0.493 which indicates that the new regression line fits better to the data.

--------------------------------------------------------------------------------

Question 7 - How might these results differ by geography? Create a variable that assigns each observation to a geographic region (e.g., continent) and report a regression that builds on (6) by including the appropriate dummy variables. Interpret your results.

```{r regression with continents}

Dataset1$continent <- countrycode(sourcevar = Dataset1[,"Country"],
                                      origin = "country.name",
                                   destination = "continent")

view(Dataset1)
unique(Dataset1[c("continent")])

Dataset1 <- dummy_cols(Dataset1, select_columns = "continent") #used fast dummies to make dummy variables

continet_regression <- lm(LEBF20052~log(HXPC2005)+log(GDPPCUS2005) + continent_Africa +
                            continent_Americas + continent_Asia + continent_Europe
                          + continent_Oceania, Dataset1)
#all dummy variables are in the regression - to let R decide which one to drop

Regression_table4 <- msummary(continet_regression,
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                               fmt = 5,  statistic = c("conf.int",  "standard error = {std.error}", 
                                            "p-value = {p.value}"))
Regression_table4

```

When including variables that assign each observation to a geographic region (and holding them constant), the relationship between HXPC and LEBF shows a 10% increase in HXPC is associated with a 0.008624 increase in LEBF, but this remains not statistically significant. The relationship between GDPPC and LEBF sees a 10% increase in GDDPC significantly associated with a 0.331976 increase in LEBF which is a slight decrease from the output reported in (6) where a 10% increase in GDDPC was significantly associated with a 0.4114 increase in LEBF.The association between the continent of Africa and LEBF (when controlling for HXPC, GDDPC, and other continents) is statistically significant and negative (vs. Oceania). Conversely, the other continents have a positive relationship with LEBF although it is not statistically significant. The R^2 for the model of 0.641 shows good model fit and indicates that the variables in the model are able to adequately account for the variation in LEBF.

--------------------------------------------------------------------------------

Question 8 - Finally, include an interaction term between HXPC and the indicator for African countries. What are you measuring with this interaction, and why might it be meaningful? Interpret the results of this coefficient. 

```{r interaction regression}
interaction_regression <- lm(LEBF20052~log(HXPC2005) 
                          +log(GDPPCUS2005) 
                          + continent_Africa 
                          + continent_Americas 
                          + continent_Asia 
                          + continent_Europe
                          + continent_Oceania 
                          + log(HXPC2005):continent_Africa, Dataset1)

Regression_table5 <- msummary(interaction_regression,
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                              fmt = 5,  statistic = c("conf.int",  
                                                      "standard error = {std.error}", 
                                            "p-value = {p.value}"))


Regression_table5

```

With this interaction term we are measuring effect of HXPC specific to African countries. It might be meaningful to include this interaction term as it would allow us to determine how much stronger the effect of HXPC on LEBF is when the continent is Africa. The interaction term shows that for an African country, a 10% increase in health expenditure increases LEBF by 0.38514, however this relationship is not statistically significant. 
#maybe we can just say here that for africa alone the HXPC effect is an additional 0.032 life years (Casey included the individual statement )

--------------------------------------------------------------------------------

Question 9 - Why is establishing the causal relationship between GDDPC, HXPC, and LEBF difficult in a simple regression such as this? If possible, provide one key figure that highlights an identification problem in this scenario.
```{r Question No.9}
q.9_regression.1 <- lm(LEBF20052~log(GDPPCUS2005), Dataset1)
q.9_regression.2 <- lm(LEBF20052~log(HXPC2005), Dataset1)

q.9_table <- msummary(list(q.9_regression.1, q.9_regression.2, third_regression), fmt = "%.4f",
                      stars=c('*' = .1, '**' = .05, '***' = .01),  statistic = c("conf.int",
                                                                                 "standard error = 
                                                                                 {std.error}", 
                                            "p-value = {p.value}"))  
#added pvalues 
q.9_table
```

Establishing the causal relationship between GDDPC, HXPC, and LEBF in a simple regression such as this is difficult as there are many sources of variation that can complicate the causal pathway between these three variables (as shown in the DAG in Question 1). From our DAG we can see a substantial number of different sources of variation coming from GDPPC (which ultimately includes HXPC). Both GDPPC and HXPC account for a substantial amount of variation in LEBF (when we examine R^2 in the regressions for both explanatory variables on LEBF), but using theory (seen through our DAG) we can realize that there are other contributors within the data generating process that are not captured through this process. 

#would we potentially want to also talk about when GDDPC AND HXPC are included in a regression the effects change and this may show indication about why it isnt easy to make causal suggestions (e.g. when we control for GDDPC, HXPC is no loner significant - I included the third regression into the model summary just to show that it may be something we may want to speak on )

#i think we may have to include a scatterplot of the residual values for the LEBF
--------------------------------------------------------------------------------

Question 10 - What do your results from (9) and intuition suggest about the standard errors in your specification? Either justify the use of homoscedastic standard errors or implement a full specification with another, more robust method (e.g., heteroskedasticity-robust or clustered SEs). How does this change the results?
```{r Question No.10}
#i hope this works
```


--------------------------------------------------------------------------------

```{r Citations, include=FALSE}
knitr::write_bib(file = 'packages.bib') # Constructs a citation file for all packages used in this lecture. 

```




