---
name: Group - Husayn Jessa and Aidan Bodner
title: "Assignment 1"
output: html_document
date: '2022-09-30'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Assignment Intro}

name <- Sys.info()
name[7]

### Load the packages we will need for this file ####

library(tidyverse) # load the installed package for each new session of R
library(broom) # helps for storing regression output
library(here) # for file organization
library(modelsummary) # For making regression tables
library(psych) # For making summary statistics tables
library(countrycode) # To get continents from countries
library(fastDummies) # To make dummy variables

# enter file path identifiers
here("Desktop", "Graduate Studies", "4. Courses", "Fall 2022", "HAD5744H", "Assignments", "Assignment 1")

assign_data <- read.csv("Dataset 1.csv") # assign data to an object

```

```{r Clean Data}

# Scan through dataframe to see variable class types
for(values in names(assign_data)){
  print(names(assign_data[values]))
  name <- names(assign_data[values])
  print(class(assign_data[,values]))
}

# Convert all to character
assign_data[, 1:19] <- lapply(assign_data[, 1:19], as.character)

# Assign the NAs in dataset to NA
assign_data <- mutate_at(.tbl = assign_data, 
                                .vars = vars(Country:PctPop65Pl2005), 
                                .funs = ~case_when(. == "#N/A" ~ NA_character_,
                                                   . == "-" ~ NA_character_,
                                                   TRUE ~ .,
                                                   TRUE ~ as.character(NA_character_)))

# Save cleaned data
write.csv(assign_data, "Dataset 1_Clean.csv", row.names = FALSE)

# Read in cleaned data
Dataset1 <- read.csv("Dataset 1_Clean.csv")

# Convert to numerics (aside from Country)
Dataset1[, 2:19] <- lapply(Dataset1[, 2:19], as.numeric)
```

--------------------------------------------------------------------------------

Question 1: Draw a preliminary DAG for the following variables: LEBF, GDPPC
 HXPC, total fertility rate, and any other covarites of relevance;ensure
relationships between the other independent variables is included
```{r Question No.1}


```
See attached DAG.

--------------------------------------------------------------------------------
Question 2: What does your DAG tell you about interpreting any regression coefficients
causally 

A DAG may only allow for causal interpretations of regression coefficients if all the assumptions used in creating and determining relationships are correct (i.e., all variables in model are justified and the relationships between them are correct), as well as if all open back door paths are closed (or have a collider on them). When examining our DAG, we are not able to interpret the regression coefficients causally as we cannot guarantee that all of our assumptions are indeed correct; however, we would be one step closer to any causal interpretation by controlling for variation along paths that we are not interested in (closing open back doors).

--------------------------------------------------------------------------------

Question 3: Make a table providing summary statistics for your variables;
table should include the mean, standard deviation and sample size for each variable
```{r summary table}

summary_table <- describe(Dataset1[ ,c("LEBF20052","maxINFM20052","GDPPCUS2005", "HXPC2005","PctHXPUB2005",
                   "TotFertRate2005","AdolFertRt2005","FtoMPrimaryEnrl2005ONY",
                   "PctUrb2005", "Sanitation2005ONY","ImprWaterUrb2005ONY",
                   "ImpWatRur2005ONY", "FLFPR2005", "PctPop0142005", "PctPop65Pl2005")],
                  fast=TRUE) 
summary_table <- summary_table[ ,-(1), drop = FALSE] #drop first column which corresponds to variable number in dataframe
summary_table # output summary table


```

--------------------------------------------------------------------------------

Question 4 - Regress LEBF on HXPC. Report the coefficients,standard errors, confidence intervals, p-values, R2, and sample size in a regression table. Interpret the table, noting the economic and statistical significance of the relationship. What is the association between a 1,000-unit increase in HXPC and LEBF? (Note that HXPC is measured in dollars.)
```{r Question No.4}
first_regression <- lm(LEBF20052~HXPC2005, Dataset1)
Regression_table1 <- msummary(first_regression, 
                              stars=c('*' = .1, '**' = .05, '***' = .01))         
Regression_table1
```
HXPC is positively and significantly associated with LEBF. A $1,000 increase in HXPC is significantly associated with a 4 unit increase in LEBF.


--------------------------------------------------------------------------------

Question 5 - Regress LEBF on HXPC and GDPPC. Discuss the results of this regression relative
to those from (4).
```{r Question No.5}

second_regression <- lm(LEBF20052~HXPC2005+GDPPCUS2005, Dataset1)
Regression_table2 <- msummary(list(first_regression,third_regression), 
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                              fmt = 5)
Regression_table2
```
When controlling for GDPPC, the relationship between HXPC and LEBF shows a negative relationship which is not statistically significant. Comparing this relationship with the results from (4), HXPC was significantly associated with a positive increase in LEBF, which makes sense that the current output is not statistically significant as we would expect an increase in health expenditure to be associated with an increase in life expectancy.
When controlling for HXPC, GDPPC is associated with a 0.0005 increase in LEBF. 

--------------------------------------------------------------------------------

Question 6 - Do you recommend a nonlinear transformation for either GDPPC, HXPC, or LEBF? If so, defend your choice and repeat the regression in (5) with the appropriate transformations. Interpret how your results have changed. [10 points]
```{r Question No.6}

# Visually, look and see how well the observations fit the linear model

vtable(Dataset1)
attach(Dataset1)
hist(GDPPCUS2005)        
hist(log(GDPPCUS2005))
hist(HXPC2005)
hist(log(HXPC2005))

ggplot(Dataset1, aes(x = HXPC2005, y = LEBF20052)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red")

ggplot(Dataset1, aes(x = GDPPCUS2005, y = LEBF20052)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red")


#The histograms of GDPPC and HXPC2005 show that their data is rightly skewed and thus is likely 
#to produce outliers. This can effect how well the regression model behaves and make it 
#statistically weak. I recommend, doing a log transformation of these two variables because
#it will make the big observations in the data smaller and thus closer to the other variables 
#in the data. This will help reduce the skew and help the model behave more effectively.
#The histograms of the log transformed variables show that when a log transformation is performed
#the data looks more like a normal distribution. 


# model does not fit observations well at all. for HXPC and LEBF, the majority of the observations are centred around 1
# We can also use goodness of fit (R^2) to check and see if our model is fitting the data
# R^2 from question 4 shows that R^2 between HXPC and lEBF is 0.203 and R^2 between GDPPC and LEBF is 0.256 numerically indicating that the fit can likely be improved.



```
The histograms of GDPPC and HXPC show that their data is rightly skewed and thus is likely to produce outliers. Additionally, looking at how well the observations fit around the regression line, we can see that the plots for both GDDPC and HXPC do not fit the regression line well. We recommend, doing a log transformation of these two variables because it will make the big observations in the data smaller and thus closer to the other variables in the data. This will help reduce the skew and help the model behave more effectively.The histograms of the log transformed variables show that when a log transformation is performed the data looks approximately fits a normal distribution which is helpful for drawing statistical inference. 

--------------------------------------------------------------------------------

```{r Question No. 6 pt 2}
third_regression <- lm(LEBF20052~log(HXPC2005)+log(GDPPCUS2005), Dataset1)
Regression_table3 <- msummary(list(third_regression, fourth_regression), 
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                              fmt = "%.4f")
Regression_table3
```
Applying a non-linear transformation is necessary in order to reduce the extreme effects of outliers on our regression outputs. Log transforming the predictor variables in the regression model is one way in which we can achieve this. It makes sense to log transform the independent variables in the model by applying a natural log, as we can directly compare the regression output to those in (5) as the output stays in the same units. We are also able to apply the natural log as we do not have any zero-valued data.


By log transforming both HXPC and GDPPC we are provided with new regression coefficients. The regression coefficient of log(HXPC2005) is now 0.8886 which is substantially different than the non-log'd coefficient -0.0014. The new regression coefficient indicates that for every 10% increase in HXPC (when GDPPC is held constant), the LEBF will increase by 0.089. Intuitively, life expectancy should increase as there is more health expenditure within a country so these new results make more sense which speaks to the value of transforming the HXPC variable. The results however remain insignificant. The regression coefficient for log(GDPPCUS2005) also changed to 4.114 whihc is an increase from the non-log'd coefficient of 0.0005. Both coefficients were deemed as statistically significant. The new regression coefficient indicates that for every 10% increase in GDP (when HXPC is held constant) there is a 0.4114 increase in life expectancy at birth for females. We can also see that the R^2 value has increased from 0.252 to 0.493 which indicates that the new regression line fits better to the data.
--------------------------------------------------------------------------------

Question 7 - How might these results differ by geography? Create a variable that assigns each observation to a geographic region (e.g., continent) and report a regression that builds on (6) by including the appropriate dummy variables. Interpret your results.
```{r Question No.7}

Dataset1$continent <- countrycode(sourcevar = Dataset1[,"Country"],
                                      origin = "country.name",
                                   destination = "continent")

view(Dataset1)
unique(Dataset1[c("continent")])


Dataset1 <- dummy_cols(Dataset1, select_columns = "continent") 

continet_regression <- lm(LEBF20052~log(HXPC2005)+log(GDPPCUS2005) + continent_Africa +
                            continent_Americas + continent_Asia + continent_Europe
                          + continent_Oceania, Dataset1)

Regression_table4 <- msummary(continet_regression,
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                               fmt = 5)
Regression_table4




```
When including variables that assign each observation to a geographic region (and holding them constant), the relationship between HXPC and LEBF shows a 10% increase in HXPC is associated with a 0.00821955 increase in LEBF, but this remains not statistically significant. The relationship between GDPPC and LEBF sees a 10% increase in GDDPC significantly associated with a 0.3164069 increase in LEBF which is a slight decrease from the output reported in (6) where a 10% increase in GDDPC was significantly associated with a 0.3921442 increase in LEBF.


--------------------------------------------------------------------------------

Question 8 - Finally, include an interaction term between HXPC and the indicator for African countries. What are you measuring with this interaction, and why might it be meaningful? Interpret the results of this coefficient. 
```{r Quesiton No.8}
interaction_regression <- lm(LEBF20052~log(HXPC2005) 
                          + log(GDPPCUS2005) 
                          + continent_Africa 
                          + continent_Americas 
                          + continent_Asia 
                          + continent_Europe
                          + continent_Oceania 
                          + log(HXPC2005):continent_Africa, Dataset1)

Regression_table5 <- msummary(interaction_regression,
                              stars=c('*' = .1, '**' = .05, '***' = .01),
                              fmt = 5)

Regression_table5
```

With this interaction term we are measuring effect of HXPC specific to African countries. It might be meaningful to include this interaction term as it would allow us to determine how much stronger the effect of HXPC on LEBF is when the continent is Africa. The interaction term shows that for an African country, a 10% increase in health expenditure increases LEBF by 0.006318112, however this relationship is not statistically significant.


--------------------------------------------------------------------------------

Question 9 - Why is establishing the causal relationship between GDDPC, HXPC, and LEBF difficult in a simple regression such as this? If possible, provide one key figure that highlights an identification problem in this scenario. (Note that there are multiple possible answers for this problem; the goal is to think critically about the causal identification.)
```{r Question No.9}

```


--------------------------------------------------------------------------------

Question 10 - What do your results from (9) and intuition suggest about the standard errors in your specification? Either justify the use of homoscedastic standard errors or implement a full specification with another, more robust method (e.g., heteroskedasticity-robust or clustered SEs). How does this change the results?
```{r Question No.10}

```

--------------------------------------------------------------------------------

```{r Citations, include=FALSE}
knitr::write_bib(file = 'packages.bib') # Constructs a citation file for all packages used in this lecture. 

```




