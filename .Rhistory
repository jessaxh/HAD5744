Regression_table3
```
Applying a non-linear transformation is necessary in order to reduce the extreme effects of outliers on our regression outputs. Log transforming the predictor variables in the regression model is one way in which we can achieve this. It makes sense to log transform the independent variables in the model by applying a natural log, as we can directly compare the regression output to those in (5) as the output stays in the same units. We are also able to apply the natural log as we do not have any zero-valued data.
By log transforming both HXPC and GDPPC we are provided with new regression coefficients. The regression coefficient of log(HXPC2005) is now 0.8886 which is substantially different than the non-log'd coefficient -0.0014. The new regression coefficient indicates that for every 10% increase in HXPC (when GDPPC is held constant), the LEBF will increase by 0.089. Intuitively, life expectancy should increase as there is more health expenditure within a country so these new results make more sense which speaks to the value of transforming the HXPC variable. The results however remain statisically insignificant. The regression coefficient for log(GDPPCUS2005) also changed to 4.114 which is an increase from the non-log'd coefficient of 0.0005. Both coefficients were deemed as statistically significant. The new regression coefficient indicates that for every 10% increase in GDP (when HXPC is held constant) there is a 0.4114 increase in life expectancy at birth for females. We can also see that the R^2 value has increased from 0.252 to 0.493 which indicates that the new regression line fits better to the data.
--------------------------------------------------------------------------------
Question 7 - How might these results differ by geography? Create a variable that assigns each observation to a geographic region (e.g., continent) and report a regression that builds on (6) by including the appropriate dummy variables. Interpret your results.
```{r regression with continents}
Dataset1$continent <- countrycode(sourcevar = Dataset1[,"Country"],
origin = "country.name",
destination = "continent")
view(Dataset1)
unique(Dataset1[c("continent")])
Dataset1 <- dummy_cols(Dataset1, select_columns = "continent") #used fast dummies to make dummy variables
continet_regression <- lm(LEBF20052~log(HXPC2005)+log(GDPPCUS2005) + continent_Africa +
continent_Americas + continent_Asia + continent_Europe
+ continent_Oceania, Dataset1)
#all dummy variables are in the regression - to let R decide which one to drop
Regression_table4 <- msummary(list("continent_reg"=continet_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
fmt = 5,  statistic = c("conf.int",  "standard error = {std.error}",
"p-value = {p.value}"))
Regression_table4
```
When including variables that assign each observation to a geographic region (and holding them constant), the relationship between HXPC and LEBF shows a 10% increase in HXPC is associated with a 0.008624 increase in LEBF, but this remains not statistically significant. The relationship between GDPPC and LEBF sees a 10% increase in GDDPC significantly associated with a 0.331976 increase in LEBF which is a slight decrease from the output reported in (6) where a 10% increase in GDDPC was significantly associated with a 0.4114 increase in LEBF.The association between the continent of Africa and LEBF (when controlling for HXPC, GDDPC, and other continents) is statistically significant and negative (vs. Oceania). Conversely, the other continents have a positive relationship with LEBF although it is not statistically significant. The R^2 for the model of 0.641 shows good model fit and indicates that the variables in the model are able to adequately account for the variation in LEBF.
--------------------------------------------------------------------------------
Question 8 - Finally, include an interaction term between HXPC and the indicator for African countries. What are you measuring with this interaction, and why might it be meaningful? Interpret the results of this coefficient.
```{r interaction regression}
interaction_regression <- lm(LEBF20052~log(HXPC2005)
+log(GDPPCUS2005)
+ continent_Africa
+ continent_Americas
+ continent_Asia
+ continent_Europe
+ continent_Oceania
+ log(HXPC2005):continent_Africa, Dataset1)
Regression_table5 <- msummary(list("interaction_reg"=interaction_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
fmt = 5,  statistic = c("conf.int",
"standard error = {std.error}",
"p-value = {p.value}"))
Regression_table5
```
With this interaction term we are measuring effect of HXPC specific to African countries. It might be meaningful to include this interaction term as it would allow us to determine how much stronger the effect of HXPC on LEBF is when the continent is Africa. The interaction term shows that for an African country, a 10% increase in health expenditure increases LEBF by 0.038514, however this relationship is not statistically significant.
When we look at the interaction between HXPC and the continent of Africa we see that the regression coefficient is 0.32, which indicates that for Africa, a 10% increase in health expenditure leads to an additional 0.032 life years on top of the general effect of health expenditure which would be 0.0066 life years for ever 10% increase in health expenditure. It is the combination of these two values that lets us identify that the cumulative effect of a 10% increase in health expenditure in Africa increases LEBF by 0.0385.
--------------------------------------------------------------------------------
Question 9 - Why is establishing the causal relationship between GDDPC, HXPC, and LEBF difficult in a simple regression such as this? If possible, provide one key figure that highlights an identification problem in this scenario. (Note that there are multiple possible answers for this problem; the goal is to think critically about the causal identification.)
```{r Question No.9}
q.9_regression.1 <- lm(LEBF20052~log(GDPPCUS2005), Dataset1)
q.9_regression.2 <- lm(LEBF20052~log(HXPC2005), Dataset1)
q.9_table <- msummary(list("LEBF_log(GDP)"=q.9_regression.1, "LEBF_log(HXPC)"=q.9_regression.2,
"LEBF_log(GDP)+log(HXPC)"= third_regression), fmt = "%.4f",
stars=c('*' = .1, '**' = .05, '***' = .01),
statistic = c("conf.int", "standard error = {std.error}",
"p-value = {p.value}"))
q.9_table
```
Establishing the causal relationship between GDDPC, HXPC, and LEBF in a simple regression such as this is difficult as there are many sources of variation that can complicate the causal pathway between these three variables (as shown in the DAG in Question 1). This relationship is further complicated when the relationship between continents (countries) are taken into consideration, as from our DAG they drive much of the variation seen within GDPPC and subsequently HXPC.From our DAG we can see a substantial number of different sources of variation coming from GDPPC (which ultimately includes HXPC). Both GDPPC and HXPC account for a substantial amount of variation in LEBF (when we examine R^2 in the regressions for both explanatory variables on LEBF), but using theory (seen through our DAG) we can realize that there are other contributors within the data generating process that are not captured through this relationship. Additionally, when constructing a bivariate model, we can see that the R^2 is still lower than the univariate model examining LEBF and GDPPC, indicating that the inclusion of HXPC does not help in identifying what is associated with variation in LEBF. Moreover in this bivariate model, when controlling for GDPPC, HXPC decreases substantially from the univariate (LEBF~HXPC) model and becomes statistically insignificant. This indicates that HXPC likely has a much smaller role to play in the relationship between HXPC, GDPPC, and LEBF when GDPPC is taken into consideration. From this, we can appreciate that the DAG can help us to form testable assumptions and the models can help us to check those assumptions (to a point), but ultimately unless we are certain that we have accounted for all the variation in our outcome (through the DAG we construct), we cannot establish a causal relationship between HXPC, GDPPC, and LEBF.
--------------------------------------------------------------------------------
Question 10 - What do your results from (9) and intuition suggest about the standard errors in your specification? Either justify the use of homoscedastic standard errors or implement a full specification with another, more robust method (e.g., heteroskedasticity-robust or clustered SEs). How does this change the results?
```{r Question No.10}
#plot the residuals vs fitted values
par(mfrow = c(2, 2))
plot(interaction_regression)
#plot shows heteroskedasticity may exist
#Breusch-Pagan test for heteroskedasticity
lmtest::bptest(interaction_regression)
#the bptest is showing that the we can reject the null that the residuals are distributed with equal variance (homoscedasticty) as there is a high test statistic (BP = 49.79) and a p value < 0.05, therefore we can reject the null that the residuals are homoscedastic
#specification using both robust corrections for standard errors and autocorrelation
se_corrections<- msummary(list("homoscedastic" = interaction_regression,
"robust_se" =interaction_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
vcov =c("classical","robust"),
fmt = "%.2f", statistic = c("conf.int", "standard error = {std.error}",
"p-value = {p.value}"))
se_corrections
```
The results from question 9, and our intuition suggest that the standard errors in our specification are not homoscedastic. To check if it is accurate to use homoscedastic errors, a plot was created to look at the residual vs fitted values of our model that includes continents. We include continents to represent our theoretical assumptions outliine in our DAG, indicating that the variation of GDPPC and HXPC begins from country (continental) variation. In this residual plot, we can see that the data is not randomly spread around the 0 line and thus indicative that the use of homoscedastic standard errors may not be best practice. To confirm what we saw in the residual vs fitted plot, we conducted a Breusch-Pagan test to test for heteroskedasticity in our model. The results of our Breusch-Pagan test displayed a high test statistic and a p value < 0.05. Therefore, we reject the null hypothesis and can confirm that this regression model violates the homoscedasticity assumption.
As a result of this plot and the Breusch-Pagan test, we implemented a correction for heteroskedasticity within our model. We did not implement a correction for autocorrelation as our data was not collected over multiple time periods so it would not make sense for autocorrelation to have an impact. When we used the heteroskedasticity-robust method for our standard errors we observed that the standard errors for log(HXPC) and log(GDPPC) increased from 1.45 and 1.50 to 2.06 and 2.28 respectively. The standard errors increasing indicates that our standard errors are becoming more accurate in describing th data. We can also see that within our data that the regression coefficient for log(GDPPC) is no longer significant after this method is employed. This result is expected because the larger standard error, 2.78, observed leads to a test statistic that is smaller. Smaller test statistics are associated with larger p-values thus the loss of significance of the regression coefficient for log(GDDPC) as a result of the heteroskedasticity-robust method employed makes sense.
#i didnt talk about the other standard errors for the continents - idk if i should but get some funky things that idk how to explain like standard errors going down not up haha
--------------------------------------------------------------------------------
```{r Citations, include=FALSE}
knitr::write_bib(file = 'packages.bib') # Constructs a citation file for all packages used in this assignment.
```
knitr::opts_chunk$set(echo = TRUE)
name <- Sys.info()
name[7]
### Load the packages we will need for this file ####
library(tidyverse) # load the installed package for each new session of R
library(broom) # helps for storing regression output
library(here) # for file organization
library(modelsummary) # For making regression tables
library(psych) # For creating summary statistics table
library(countrycode) # Used to get continents from countries
library(fastDummies) # To create dummy variables
library(vtable) #Shows information about the variables in your data set
library(lmtest) #A collection of tests, data sets, and examples for diagnostic checking in linear regression models
# set working directory
here()
assign_data <- read.csv("Dataset 1.csv") # assign data to an object
# Scan through dataframe to see variable class types
for(values in names(assign_data)){
print(names(assign_data[values]))
name <- names(assign_data[values])
print(class(assign_data[,values]))
}
# Convert all to character
assign_data[, 1:19] <- lapply(assign_data[, 1:19], as.character)
# Assign the NAs in dataset to NA
assign_data <- mutate_at(.tbl = assign_data,
.vars = vars(Country:PctPop65Pl2005),
.funs = ~case_when(. == "#N/A" ~ NA_character_,
. == "-" ~ NA_character_,
TRUE ~ .,
TRUE ~ as.character(NA_character_)))
# Save cleaned data
write.csv(assign_data, "Dataset 1_Clean.csv", row.names = FALSE)
# Read in cleaned data
Dataset1 <- read.csv("Dataset 1_Clean.csv")
# Convert to numerics (aside from Country)
Dataset1[, 2:19] <- lapply(Dataset1[, 2:19], as.numeric)
describe(Dataset1)
summary_table <- describe(Dataset1[ ,c("LEBF20052","maxINFM20052","GDPPCUS2005", "HXPC2005","PctHXPUB2005",
"TotFertRate2005","AdolFertRt2005","FtoMPrimaryEnrl2005ONY",
"PctUrb2005", "Sanitation2005ONY","ImprWaterUrb2005ONY",
"ImpWatRur2005ONY", "FLFPR2005", "PctPop0142005", "PctPop65Pl2005")],
fast=TRUE)
summary_table <- summary_table[ ,-(1), drop = FALSE] #drop first column which corresponds to variable number in dataframe
summary_table
first_regression <- lm(LEBF20052~HXPC2005, Dataset1)
Regression_table1 <- msummary(first_regression, fmt = "%.4f",
stars=c('*' = .1, '**' = .05, '***' = .01),
statistic = c("conf.int",  "standard error = {std.error}",
"p-value = {p.value}")
)
Regression_table1
second_regression <- lm(LEBF20052~HXPC2005+GDPPCUS2005, Dataset1)
Regression_table2 <- msummary(list(first_regression,second_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
fmt = "%.4f",  statistic = c("conf.int",  "standard error
={std.error}",
"p-value = {p.value}"))
Regression_table2
# Visually, look and see how well the observations fit the linear model
vtable(Dataset1)
attach(Dataset1)
hist(GDPPCUS2005)
hist(log(GDPPCUS2005))
hist(HXPC2005)
hist(log(HXPC2005))
ggplot(Dataset1, aes(x = HXPC2005, y = LEBF20052)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(Dataset1, aes(x = GDPPCUS2005, y = LEBF20052)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(Dataset1, aes(x = log(HXPC2005), y = LEBF20052)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(Dataset1, aes(x = log(GDPPCUS2005), y = LEBF20052)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
third_regression <- lm(LEBF20052~log(HXPC2005)+log(GDPPCUS2005), Dataset1)
Regression_table3 <- msummary(list("non_log_reg" =second_regression,
"log_reg"= third_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
fmt = "%.4f",  statistic = c("conf.int",  "standard error
={std.error}",
"p-value = {p.value}"))
Regression_table3
Dataset1$continent <- countrycode(sourcevar = Dataset1[,"Country"],
origin = "country.name",
destination = "continent")
view(Dataset1)
unique(Dataset1[c("continent")])
Dataset1 <- dummy_cols(Dataset1, select_columns = "continent") #used fast dummies to make dummy variables
continet_regression <- lm(LEBF20052~log(HXPC2005)+log(GDPPCUS2005) + continent_Africa +
continent_Americas + continent_Asia + continent_Europe
+ continent_Oceania, Dataset1)
#all dummy variables are in the regression - to let R decide which one to drop
Regression_table4 <- msummary(list("continent_reg"=continet_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
fmt = 5,  statistic = c("conf.int",  "standard error = {std.error}",
"p-value = {p.value}"))
Regression_table4
interaction_regression <- lm(LEBF20052~log(HXPC2005)
+log(GDPPCUS2005)
+ continent_Africa
+ continent_Americas
+ continent_Asia
+ continent_Europe
+ continent_Oceania
+ log(HXPC2005):continent_Africa, Dataset1)
Regression_table5 <- msummary(list("interaction_reg"=interaction_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
fmt = 5,  statistic = c("conf.int",
"standard error = {std.error}",
"p-value = {p.value}"))
Regression_table5
q.9_regression.1 <- lm(LEBF20052~log(GDPPCUS2005), Dataset1)
q.9_regression.2 <- lm(LEBF20052~log(HXPC2005), Dataset1)
q.9_table <- msummary(list("LEBF_log(GDP)"=q.9_regression.1, "LEBF_log(HXPC)"=q.9_regression.2,
"LEBF_log(GDP)+log(HXPC)"= third_regression), fmt = "%.4f",
stars=c('*' = .1, '**' = .05, '***' = .01),
statistic = c("conf.int", "standard error = {std.error}",
"p-value = {p.value}"))
q.9_table
#plot the residuals vs fitted values
par(mfrow = c(2, 2))
plot(interaction_regression)
#plot shows heteroskedasticity may exist
#Breusch-Pagan test for heteroskedasticity
lmtest::bptest(interaction_regression)
#the bptest is showing that the we can reject the null that the residuals are distributed with equal variance (homoscedasticty) as there is a high test statistic (BP = 49.79) and a p value < 0.05, therefore we can reject the null that the residuals are homoscedastic
#specification using both robust corrections for standard errors and autocorrelation
se_corrections<- msummary(list("homoscedastic" = interaction_regression,
"robust_se" =interaction_regression),
stars=c('*' = .1, '**' = .05, '***' = .01),
vcov =c("classical","robust"),
fmt = "%.2f", statistic = c("conf.int", "standard error = {std.error}",
"p-value = {p.value}"))
se_corrections
knitr::write_bib(file = 'packages.bib') # Constructs a citation file for all packages used in this assignment.
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(here)
assign_data <- read.csv("a3_p1_sourdough_trends.csv")
View(assign_data)
assign_data %>%
summarise_all(funs(sum(is.na(.)))) # Returns no NAs, can probably remove
library(dplyr)
assign_data %>%
summarise_all(funs(sum(is.na(.)))) # Returns no NAs, can probably remove
View(assign_data)
class(assign_data$geo)
ggplot(assign_data, (aes(x=date,y=hits,group=keyword))) + geom_line() +
theme_classic() + labs(x="Date",y="Hits")
library(ggplot2)
ggplot(assign_data, (aes(x=date,y=hits,group=keyword))) + geom_line() +
theme_classic() + labs(x="Date",y="Hits")
ggplot(assign_data, (aes(x=date,y=hits,group=keyword))) + geom_line() +
theme_linedraw() + labs(x="Date",y="Hits")
ggplot(assign_data, (aes(x=date,y=hits,group=keyword))) + geom_line() +
theme_minimal() + labs(x="Date",y="Hits")
ggplot(assign_data, (aes(x = date, y = hits, group = keyword, label = keyword))) + geom_line() +
theme_minimal() + labs(x = "Date", y = "Hits")
ggplot(assign_data, (aes(x = date, y = hits, group = keyword, label = keyword))) + geom_line() +
theme_linedraw() + labs(x = "Date", y = "Hits")
ggplot(assign_data, (aes(x = date, y = hits, group = keyword, fill = keyword))) + geom_line() +
theme_linedraw() + labs(x = "Date", y = "Hits")
ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) + geom_line() +
geom_label(label = keyword) + theme_linedraw() + labs(x = "Date", y = "Hits")
library(here)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(ggrepel)
install.packages("ggrepel")
library(ggrepel)
q1_line_graph <- assign_data %>%
# Extract year
mutate(month = lubridate::year(date)) %>%
# Subset variables
select(date, hits, keyworde) %>%
# If there is more than one record per year/country, use the mean
# Keep countries/regions with records for the last 21 years
# (from 2000 to 2020 inclusive)
group_by(keyword) %>%
filter(n() == 21)
q1_line_graph <- assign_data %>%
# Extract year
mutate(month = lubridate::year(date)) %>%
# Subset variables
select(date, hits, keyworde) %>%
# If there is more than one record per year/country, use the mean
# Keep countries/regions with records for the last 21 years
# (from 2000 to 2020 inclusive)
group_by(keyword)
q1_line_graph <- assign_data %>%
# Extract year
mutate(month = lubridate::year(date)) %>%
# Subset variables
select(date, hits, keyword) %>%
# If there is more than one record per year/country, use the mean
# Keep countries/regions with records for the last 21 years
# (from 2000 to 2020 inclusive)
group_by(keyword)
q1_line_graph
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) + geom_line() +
geom_label(label = keyword) + theme_linedraw() + labs(x = "Date", y = "Hits")
q1_line_graph <- ggplot(
# The ggplot object has associated the data for the highlighted countries
assign_data,
aes(date, hits, group = keyword)
) +
# Geometric annotations that play the role of grid lines
geom_vline(
xintercept = seq(2000, 2020, by = 5),
color = "grey91",
size = .6
) +
geom_segment(
data = tibble(y = seq(-4, 3, by = 1), x1 = 2000, x2 = 2020),
aes(x = x1, xend = x2, y = y, yend = y),
inherit.aes = FALSE,
color = "grey91",
size = .6
) +
geom_segment(
data = tibble(y = 0, x1 = 2000, x2 = 2020),
aes(x = x1, xend = x2, y = y, yend = y),
inherit.aes = FALSE,
color = "grey60",
size = .8
) +
geom_vline(
aes(xintercept = "2020-03-15T00:00:00Z
"),
color = "grey40",
linetype = "dotted",
size = .8
) +
## Lines for the non-highlighted countries
geom_line(
data = assign_data,
color = "grey75",
size = .6,
alpha = .5
) +
## Lines for the highlighted countries.
# It's important to put them after the grey lines
# so the colored ones are on top
geom_line(
aes(color = group),
size = .9
)
q1_line_graph
q1_line_graph <- ggplot(
# The ggplot object has associated the data for the highlighted countries
assign_data,
aes(date, hits, group = keyword)
) +
# Geometric annotations that play the role of grid lines
geom_vline(
xintercept = seq(2000, 2020, by = 5),
color = "grey91",
size = .6
) +
geom_segment(
data = tibble(y = seq(-4, 3, by = 1), x1 = 2000, x2 = 2020),
aes(x = x1, xend = x2, y = y, yend = y),
inherit.aes = FALSE,
color = "grey91",
size = .6
) +
geom_segment(
data = tibble(y = 0, x1 = 2000, x2 = 2020),
aes(x = x1, xend = x2, y = y, yend = y),
inherit.aes = FALSE,
color = "grey60",
size = .8
) +
geom_vline(
aes(xintercept = "2020-03-15T00:00:00Z
"),
color = "grey40",
linetype = "dotted",
size = .8
) +
## Lines for the non-highlighted countries
geom_line(
data = assign_data,
color = "grey75",
size = .6,
alpha = .5
) +
## Lines for the highlighted countries.
# It's important to put them after the grey lines
# so the colored ones are on top
geom_line(
aes(color = keyword),
size = .9
)
q1_line_graph
q1_line_graph <- ggplot(
# The ggplot object has associated the data for the highlighted countries
assign_data,
aes(date, hits, group = keyword)
) +
# Geometric annotations that play the role of grid lines
geom_vline(
xintercept = seq(2000, 2020, by = 5),
color = "grey91",
size = .6
) +
geom_segment(
data = tibble(y = seq(-4, 3, by = 1), x1 = 2000, x2 = 2020),
aes(x = x1, xend = x2, y = y, yend = y),
inherit.aes = FALSE,
color = "grey91",
size = .6
) +
geom_segment(
data = tibble(y = 0, x1 = 2000, x2 = 2020),
aes(x = x1, xend = x2, y = y, yend = y),
inherit.aes = FALSE,
color = "grey60",
size = .8
) +
geom_vline(
color = "grey40",
linetype = "dotted",
size = .8
) +
## Lines for the non-highlighted countries
geom_line(
data = assign_data,
color = "grey75",
size = .6,
alpha = .5
) +
## Lines for the highlighted countries.
# It's important to put them after the grey lines
# so the colored ones are on top
geom_line(
aes(color = keyword),
size = .9
)
q1_line_graph
q1_line_graph <- ggplot(
# The ggplot object has associated the data for the highlighted countries
assign_data,
aes(date, hits, group = keyword)
) +
# Geometric annotations that play the role of grid lines
geom_vline(
xintercept = seq(2000, 2020, by = 5),
color = "grey91",
size = .6
)
q1_line_graph
q1_line_graph <- ggplot(
# The ggplot object has associated the data for the highlighted countries
assign_data,
aes(date, hits, group = keyword)
) +
# Geometric annotations that play the role of grid lines
geom_vline(
xintercept = seq(2000, 2020, by = 5),
color = "grey91",
size = .6
) +
geom_segment(
data = tibble(y = seq(-4, 3, by = 1), x1 = 2000, x2 = 2020),
aes(x = x1, xend = x2, y = y, yend = y),
inherit.aes = FALSE,
color = "grey91",
size = .6
)
q1_line_graph
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) + geom_line() + theme_linedraw() + labs(x = "Date", y = "Hits")
q1_line_graph
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) +
geom_line(aes(color = keyword)) + theme_linedraw() + labs(x = "Date", y = "Hits")
q1_line_graph
assign_data$date <- as.factor(assign_data$date)
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) +
geom_line(aes(color = keyword)) + theme_linedraw() + labs(x = "Date", y = "Hits") +
geom_vline(aes(xintercept = ref_year),
color = "grey40",
linetype = "dotted",
size = .8
)
q1_line_graph
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) +
geom_line(aes(color = keyword)) + theme_linedraw() + labs(x = "Date", y = "Hits") +
geom_vline(aes(xintercept = 2020-03-15T00:00:00Z),
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) +
geom_line(aes(color = keyword)) + theme_linedraw() + labs(x = "Date", y = "Hits") +
geom_vline(aes(xintercept = 2020-03-15T00:00:00Z),
gsub('T00:00:00Z', assign_data$date)
gsub('T00:00:00Z', assign_data)
assign_data <- read.csv("a3_p1_sourdough_trends.csv")
gsub('T00:00:00Z', assign_data)
library(stringr)
str_replace_all(assign_data$date, "T00:00:00Z")
str_replace_all(assign_data$date, "T00:00:00Z", "")
class(assign_data$date)
assign_data$date <- as.numeric(assign_data$date)
assign_data <- read.csv("a3_p1_sourdough_trends.csv")
str_replace_all(assign_data$date, "T00:00:00Z", "")
assign_data$date <- str_replace_all(assign_data$date, "T00:00:00Z", "")
assign_data$date <- as.numeric(assign_data$date)
assign_data <- read.csv("a3_p1_sourdough_trends.csv")
assign_data$date <- str_replace_all(assign_data$date, "T00:00:00Z", "")
assign_data$date <- as.factor(assign_data$date)
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) +
geom_line(aes(color = keyword)) + theme_linedraw() + labs(x = "Date", y = "Hits") +
geom_vline(aes(xintercept = 2020-03-15),
color = "grey40",
linetype = "dotted",
size = .8
)
q1_line_graph
geom_vline()
?geom_vline
q1_line_graph <- ggplot(assign_data, (aes(x = date, y = hits, group = keyword))) +
geom_line(aes(color = keyword)) + theme_linedraw() + labs(x = "Date", y = "Hits") +
geom_vline(aes(xintercept = 2020-03-15),
color = "grey40",
)
q1_line_graph
